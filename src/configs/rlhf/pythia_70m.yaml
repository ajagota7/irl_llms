# Configuration for Pythia-70M RLHF

# Model settings
model:
  name: "EleutherAI/pythia-70M"
  learning_rate: 1e-5
  ppo_epochs: 4
  init_kl_coef: 0.2
  target: 6
  cliprange: 0.2
  cliprange_value: 0.2
  vf_coef: 0.1
  adap_kl_ctrl: true
  use_score_norm: true
  ratio_threshold: 10.0
  batch_size: 128
  mini_batch_size: 8
  forward_batch_size: 8
  gradient_accumulation_steps: 8
  reward_model: "facebook/roberta-hate-speech-dynabench-r4-target"
  use_raw_logits: false
  
  # Generation parameters
  generation:
    min_length: 5
    output_min_length: 15
    output_max_length: 20
    do_sample: true
    top_k: 0.0
    top_p: 1.0

# Training parameters
training:
  num_train_epochs: 100
  save_freq: 20
  eval_freq: 20
  seed: 42

# Dataset settings
dataset:
  name: "allenai/real-toxicity-prompts"
  toxicity_threshold: 0.3
  input_min_text_length: 15
  input_max_text_length: 20
  test_size: 0.1

# Output settings
output:
  push_to_hub: true
  organization: null
  repository_name: "pythia-70m-detox"

# WandB settings
wandb:
  project: "irl_llms"
  entity: null
  name: null