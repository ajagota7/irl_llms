# Configuration for Llama-3.2-3B RLHF

# Model settings
model:
  name: "meta-llama/Llama-3.2-3B"
  learning_rate: 1e-6  
  ppo_epochs: 4
  init_kl_coef: 0.8   
  target: 1.5         
  cliprange: 0.2       
  cliprange_value: 0.2 
  vf_coef: 0.1         
  adap_kl_ctrl: true
  use_score_norm: true
  ratio_threshold: 10.0 
  batch_size: 8       
  mini_batch_size: 1   
  forward_batch_size: 1
  gradient_accumulation_steps: 8
  reward_model: "s-nlp/roberta_toxicity_classifier"
  use_raw_logits: true
  
  # More conservative generation parameters
  generation:
    min_length: 5
    output_min_length: 15
    output_max_length: 20
    do_sample: true
    top_k: 0.0          
    top_p: 1.0     

# Training parameters
training:
  num_train_epochs: 100
  save_freq: 20        
  eval_freq: 20        
  seed: 42

# Dataset settings
dataset:
  name: "allenai/real-toxicity-prompts"
  toxicity_threshold: 0.3
  input_min_text_length: 15
  input_max_text_length: 20
  test_size: 0.1

# Output settings
output:
  push_to_hub: true
  organization: null
  repository_name: "llama-3-2-3b-detox"

# WandB settings
wandb:
  project: "irl_llms"
  entity: null
  name: null
