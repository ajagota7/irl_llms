# Configuration for Real End-to-End Model Test
# Replace these paths with your actual model paths

models:
  base:
    path: "EleutherAI/pythia-70m"  # Base Pythia-70m model
    description: "Original Pythia-70m model"
  
  detox_epoch_20:
    path: "ajagota71/pythia-70m-s-nlp-detox-checkpoint-epoch-20"
    description: "Detoxified Pythia-70m model (epoch 20)"
    
  detox_epoch_40:
    path: "ajagota71/pythia-70m-s-nlp-detox-checkpoint-epoch-40"
    description: "Detoxified Pythia-70m model (epoch 40)"
    
  detox_epoch_60:
    path: "ajagota71/pythia-70m-s-nlp-detox-checkpoint-epoch-60"
    description: "Detoxified Pythia-70m model (epoch 60)"
    
  detox_epoch_80:
    path: "ajagota71/pythia-70m-s-nlp-detox-checkpoint-epoch-80"
    description: "Detoxified Pythia-70m model (epoch 80)"
    
  detox_epoch_100:
    path: "ajagota71/pythia-70m-s-nlp-detox-checkpoint-epoch-100"
    description: "Detoxified Pythia-70m model (epoch 100)"

# Generation parameters
generation:
  max_new_tokens: 50
  temperature: 0.7
  do_sample: true
  top_p: 0.9

# Dataset parameters
dataset:
  name: "allenai/real-toxicity-prompts"
  split: "train"
  sample_size: 100  # Increased to 100 prompts
  filter_toxic: true  # Filter for more toxic prompts
  min_toxicity_score: 0.5  # Minimum toxicity score to include

# Classifiers
classifiers:
  toxic_bert:
    model: "unitary/toxic-bert"
    return_all_scores: true
    device: 0  # GPU
  
  roberta_toxicity:
    model: "s-nlp/roberta_toxicity_classifier"
    return_all_scores: true
    device: 0  # GPU
  
  dynabench_hate:
    model: "facebook/roberta-hate-speech-dynabench-r4-target"
    return_all_scores: true
    device: 0  # GPU

# Output settings
output:
  directory: "real_model_results"
  save_formats: ["csv", "json", "txt"]
  include_summary: true 